# # -*- coding: utf-8 -*-
# """eyetracking.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1ZxxhNMI8VR7VlsvHbVfvzxsEAld3IM_V
# """

# import urllib.request
# import bz2  # Correct module

# url = "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
# file_name = "shape_predictor_68_face_landmarks.dat.bz2"

# # Download the file
# print("Downloading model...")
# urllib.request.urlretrieve(url, file_name)

# # Extract the .bz2 file
# with bz2.BZ2File(file_name) as fr, open("shape_predictor_68_face_landmarks.dat", "wb") as fw:
#     fw.write(fr.read())

# print("Download and extraction complete!")

# Commented out IPython magic to ensure Python compatibility.
# %pip install cmake
# %pip install dlib
import cv2
import dlib
import numpy as np

# Load face detector and landmark predictor
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")  # Download required

# Function to get eye aspect ratio (EAR) - Used for blinking detection if needed
def get_eye_aspect_ratio(eye_points):
    A = np.linalg.norm(eye_points[1] - eye_points[5])
    B = np.linalg.norm(eye_points[2] - eye_points[4])
    C = np.linalg.norm(eye_points[0] - eye_points[3])
    return (A + B) / (2.0 * C)

# Indices for left and right eye in 68-point landmark model
LEFT_EYE_INDICES = list(range(36, 42))
RIGHT_EYE_INDICES = list(range(42, 48))

# Open webcam
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)

    for face in faces:
        landmarks = predictor(gray, face)
        left_eye = np.array([[landmarks.part(n).x, landmarks.part(n).y] for n in LEFT_EYE_INDICES])
        right_eye = np.array([[landmarks.part(n).x, landmarks.part(n).y] for n in RIGHT_EYE_INDICES])

        # Draw eye contours
        cv2.polylines(frame, [left_eye], True, (0, 255, 0), 2)
        cv2.polylines(frame, [right_eye], True, (0, 255, 0), 2)

        # Eye aspect ratio calculation
        left_ear = get_eye_aspect_ratio(left_eye)
        right_ear = get_eye_aspect_ratio(right_eye)

        # Draw circle at the center of the eyes
        left_eye_center = np.mean(left_eye, axis=0).astype(int)
        right_eye_center = np.mean(right_eye, axis=0).astype(int)
        cv2.circle(frame, tuple(left_eye_center), 2, (255, 0, 0), -1)
        cv2.circle(frame, tuple(right_eye_center), 2, (255, 0, 0), -1)

        # Display EAR value (optional)
        cv2.putText(frame, f'Left EAR: {left_ear:.2f}', (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        cv2.putText(frame, f'Right EAR: {right_ear:.2f}', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

    cv2.imshow("Eye Tracking", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

